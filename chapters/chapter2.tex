\chapter{Literature Review}
\label{chap:lr}
\chaptermark{Second Chapter Heading}

This chapter is devoted to a review of the literature, which is fundamental for solving the tasks set in our study. The focus is on the use of unsupervised contrastive learning methods to extract features from various datasets, for example, in medicine. 

Section I describes the principles of contrastive learning, its application in areas with limited labeled data. Section II covers the main methods for dimensionality reduction and visualization of high-dimensional data.

\section{Unsupervised Contrastive Learning Approaches}
Contrastive learning is a deep learning technique that is able to derive meaningful representations from data without relying on labels. It focuses on contrasting positive and negative sample pairs and can be used for any type of data, given appropriate augmentations exist.

\subsection{Foundations and Methodological Innovations}

In their work on SimCLR, Chen et al. \cite{tsimcne} described an algorithm for effective contrastive learning and further visualization of data in 2D. SimCLR generates augmented versions of one image, treating them as "positive" pairs and other images as "negative" pairs. Then, the model learns to combine the features of positive pairs and separate the features of negative pairs in the embedding space: a basic neural network extracts elements from images, and then a projection head maps these elements to the space where contrast loss is applied. The focus on different augmentation strategies helps the model to remember the important characteristics needed to understand complex medical images. In addition, using many images increases the number of negative examples, increasing the model's ability to distinguish between different images.

The Momentum Contrast (MoCo) framework by He et al. \cite{moco} further advances the field by introducing a dynamic queue of representations and a momentum-updated encoder. They offer the solution to problems related to time variability and diversity of patient medical data sets. Similarly, a study by BYOL by Grill et al. \cite{byol} gets rid of the need for explicit negative indicators by implementing a new approach that works well with different sets of medical data.

The work by Azizi et al. \cite{azizi} focuses on using large-scale self-supervised models for medical image classification. It shows how big self-learning models can help better use the vast number of medical images that do not have labels and improve and automate medical diagnosis tools.

Sharma et al. \cite{sharma2023auc} addressed the limitations associated with large batch sizes in contrastive learning. They introduced the AUC-Contrastive Learning (AUC-CL) framework, which integrates the area under the ROC curve (AUC) maximization with contrastive learning principles. This approach reduces the dependency on large batch sizes, a common challenge in self-supervised learning frameworks such as SimCLR and MoCo.

\section{Dimensionality reduction for visualisation}

This section explores several pivotal algorithms that have significantly contributed to the field, particularly in the context of 2D visualization of datasets.

One of the foundational techniques in dimensionality reduction is the Locally Linear Embedding (LLE), introduced by Roweis and Saul \cite{roweis2000nonlinear}. LLE is a method of studying the structure of the data that focuses on keeping local groupings unchanged, which is really useful when working with confusing or distorted data. However, LINE may not always be useful for understanding the general layout of data, which may make it less useful for tasks that require a complete overview of the dataset."

Building on the concept of neighborhood preservation, Stochastic Neighbor Embedding (SNE), developed by Hinton and Roweis (2003) \cite{hinton2002stochastic}, introduced a probabilistic framework for dimensionality reduction. SNE aims to maintain similarities between pairs in a low-dimensional space, producing the visualization of clusters or groups within the data. Despite its strengths, SNE's cost function is difficult to optimize, and the algorithm is prone to a "crowding problem," where dissimilar data points collapse onto each other in the reduced space.

To address these limitations, t-SNE (t-distributed Stochastic Neighbor Embedding), as proposed by van der Maaten and Hinton (2008) \cite {van2008visualizing}, uses a t-distribution to measure similarities in the low-dimensional space. This adjustment solves the crowding problem and has made t-SNE a popular choice for visualizing complex datasets. Nevertheless, t-SNE's computational complexity and tendency to form arbitrary clusters due to its sensitivity to hyperparameters can be problematic, especially when interpreting the results scientifically.

In response to the scalability and interpretability challenges of t-SNE, UMAP (Uniform Manifold Approximation and Projection), introduced by McInnes et al. (2018) \cite{mcinnes2018umap}, offers an alternative. UMAP reduces computational time and better preserves the global structure of the data, making a more interpretable mapping from high-dimensional to low-dimensional space.

LargeVis by Tang et al. \cite{tang2016visualizing} and TriMap by Amid and Warmuth \cite {amid2019trimap} further advance in the field, introducing new approaches to balance the preservation of local and global data structures. LargeVis, for example, succeded in handling very large datasets through its efficient neighborhood selection algorithm. TriMap, on the other hand, uses a triplet-based loss function to maintain global relationships.

Parametric mappings is an important development that makes these visualization techniques more adaptable to new data points. Van der Maaten explored this idea \cite{van2009learning} in the context of t-SNE and produced a solution that allows embedding out-of-sample points without re-running the entire algorithm. This parametric approach is promising for real-time data analysis and interactive visualization applications, although it can sometimes sacrifice the detailed structure obtained by nonparametric methods.